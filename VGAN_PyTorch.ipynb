{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGAN PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "VN_6YGbe9AF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ndu94TjF9P5v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision\n",
        "!pip install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6prMXpq9X0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XtpRsVM19l1m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Logger class\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "from tensorboardX import SummaryWriter\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "\n",
        "\n",
        "class Logger:\n",
        "\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "\n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "        \n",
        "        if format=='NHWC':\n",
        "            images = images.transpose(1,3)\n",
        "        \n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(16, 16))\n",
        "        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        if plot_horizontal:\n",
        "            display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "        \n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "        if isinstance(d_pred_real, torch.autograd.Variable):\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if isinstance(d_pred_fake, torch.autograd.Variable):\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "        \n",
        "        \n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch,num_epochs, n_batch, num_batches)\n",
        "             )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2WJmBiO39qSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Dataset class\n",
        "\n",
        "def mnist_data():\n",
        "    compose = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
        "        ])\n",
        "    out_dir = './dataset'\n",
        "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
        "\n",
        "# Load data\n",
        "data = mnist_data()\n",
        "\n",
        "# Create loader with data, so that we can iterate over it\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
        "# Num batches\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QxxfOXFz_MNV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Discriminator\n",
        "\n",
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer discriminative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        n_features = 784\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(256, n_out),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "discriminator = DiscriminatorNet()\n",
        "\n",
        "if(torch.cuda.is_available):\n",
        "    discriminator = discriminator.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kk7EIYP8_dcl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Dimensionality changing \n",
        "\n",
        "def images_to_vectors(images):\n",
        "    return images.view(images.size(0), 784)\n",
        "\n",
        "def vectors_to_images(vectors):\n",
        "    return vectors.view(vectors.size(0), 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52RBcLMD_gjr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generator\n",
        "\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer generative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 100\n",
        "        n_out = 784\n",
        "        \n",
        "        self.hidden0 = nn.Sequential(\n",
        "            nn.Linear(n_features, 256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(            \n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024, n_out),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "generator = GeneratorNet()\n",
        "\n",
        "if(torch.cuda.is_available):\n",
        "    generator = generator.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2tdhQYw4_kQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Random noise sampler\n",
        "\n",
        "def noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-fxrihl_nXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Optimizers\n",
        "\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMOc5NVL_qmD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loss fucntion\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EiIdVe_H_tFX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Target vectors\n",
        "\n",
        "def ones_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    return data\n",
        "\n",
        "def zeros_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4xhUf10_wTy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Discriminator Trainer\n",
        "\n",
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    N = real_data.size(0)\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction_real = discriminator(real_data.cuda())\n",
        "    prediction_real = prediction_real.cuda()\n",
        "    # Calculate error and backpropagate\n",
        "    error_real = loss(prediction_real.cuda(), ones_target(N).cuda())\n",
        "    error_real = error_real.cuda()\n",
        "    error_real.backward()\n",
        "\n",
        "    # 1.2 Train on Fake Data\n",
        "    prediction_fake = discriminator(fake_data.cuda())\n",
        "    prediction_fake = prediction_fake.cuda()\n",
        "    # Calculate error and backpropagate\n",
        "    error_fake = loss(prediction_fake.cuda(), zeros_target(N).cuda())\n",
        "    error_fake = error_fake.cuda()\n",
        "    error_fake.backward()\n",
        "    \n",
        "    # 1.3 Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error and predictions for real and fake inputs\n",
        "    return error_real + error_fake, prediction_real, prediction_fake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gxzn9Bb0_1WZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generator Trainer\n",
        "\n",
        "def train_generator(optimizer, fake_data):\n",
        "    N = fake_data.size(0)\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data.cuda())\n",
        "    prediction = prediction.cuda()\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction.cuda(), ones_target(N).cuda())\n",
        "    error = error.cuda()\n",
        "    error.backward()\n",
        "\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2Fa26P9_4nf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "\n",
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_WIzNZu_7wo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training\n",
        "\n",
        "# Create logger instance\n",
        "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
        "\n",
        "# Total number of epochs to train\n",
        "num_epochs = 200\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "        N = real_batch.size(0)\n",
        "\n",
        "        # 1. Train Discriminator\n",
        "        real_data = Variable(images_to_vectors(real_batch).cuda())\n",
        "\n",
        "        # Generate fake data and detach \n",
        "        # (so gradients are not calculated for generator)\n",
        "        fake_data = generator((noise(N).cuda().detach()))\n",
        "\n",
        "        # Train D\n",
        "        d_error, d_pred_real, d_pred_fake = \\\n",
        "              train_discriminator(d_optimizer, real_data.cuda(), fake_data.cuda())\n",
        "\n",
        "        # 2. Train Generator\n",
        "\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(N).cuda())\n",
        "\n",
        "        # Train G\n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "\n",
        "        # Log batch error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "          \n",
        "          \n",
        "        # Display Progress every few batches\n",
        "        if (n_batch%100) == 0: \n",
        "            test_images = vectors_to_images(generator(test_noise.cuda()))\n",
        "            test_images = test_images.data\n",
        "            \n",
        "            logger.log_images(\n",
        "                test_images.cpu(), num_test_samples, \n",
        "                epoch, n_batch, num_batches\n",
        "            );\n",
        "            \n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMVXQfbRAEq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}